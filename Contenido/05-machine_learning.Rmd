---
title: "Machine Learning"
subtitle: "Aprende R"
author: "Xopre Rodr√≠guez Gallego"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
codification: "UTF-8"
output:
  # ioslides_presentation:
  #   widescreen: true
  #   transition: slower
  #   notes: true
  rmdformats::material:
    highlight: kate
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(magrittr)
library(ggplot2)
library(dplyr)
```

# Introducci√≥n

## Introducci√≥n

El aprendizaje autom√°tico (Machine Learning) es un campo apasionante que combina estad√≠sticas, computaci√≥n y matem√°ticas para predecir patrones y extraer conocimiento √∫til de los datos. En este tutorial, exploraremos conceptos b√°sicos usando el conjunto de datos `iris` y dos m√©todos: los modelos lineales y los splines.

## ¬øQu√© es el *machine learning*?

El *machine learning* es una rama de la inteligencia artificial que se enfoca en el desarrollo de algoritmos y modelos que permiten a las computadoras aprender a partir de los datos. Estos modelos pueden ser usados para hacer predicciones, clasificar datos, detectar patrones y mucho m√°s.

## Aprendizaje supervisado y no supervisado

En el aprendizaje supervisado, los modelos se entrenan con datos etiquetados, es decir, datos que tienen una variable objetivo conocida. En el aprendizaje no supervisado, los modelos se entrenan con datos no etiquetados, es decir, datos que no tienen una variable objetivo.

## M√©tricas de error

Para evaluar el desempe√±o de los modelos, se utilizan diferentes m√©tricas de error, como el error cuadr√°tico medio, el error absoluto medio, la precisi√≥n, el *recall*, la *F1-score*, entre otros.

Depende del problema y del tipo de datos cu√°l es la m√©trica m√°s adecuada a utilizar. Categ√≥rico vs. Num√©rico.

# Ejemplos de uso

## Ejemplos de uso

Los modelos de *machine learning* se utilizan en una amplia variedad de campos, como la medicina, la biolog√≠a, la econom√≠a, la ingenier√≠a, la meteorolog√≠a, la rob√≥tica, la publicidad, el comercio electr√≥nico, la seguridad, entre otros.

- Predicci√≥n del confort t√©rmico en exteriores.
- Identificaci√≥n de anomal√≠as en una central el√©ctrica.
- Predicci√≥n de la demanda de energ√≠a el√©ctrica.
- Detecci√≥n de enfermedades.
- An√°lisis de sentimientos en redes sociales.

# Conjuntos de datos

## Conjuntos de datos

En este caso vamos a ver algunos conjuntos de datos que pueden seros √∫tiles, como alternativas a los datos que todav√≠a pod√©is estar buscando. En concreto:

- **iris** üå∏: Clasificaci√≥n de flores (setosa, versicolor, virginica) con 4 caracter√≠sticas.
- **palmerpenguins ** üêß: Caracter√≠sticas de ping√ºinos de 3 especies.
- **PlantGrowth** üå±: Peso de plantas bajo diferentes tratamientos.
- **ChickWeight** üê£: Crecimiento de pollos con distintas dietas.
- **esoph** üç∑: Relaci√≥n entre alcohol/tabaco y c√°ncer de es√≥fago.
- **biocLite** (Bioconductor) üß¨: Datos gen√≥micos y de expresi√≥n g√©nica.

Veremos ahora la cabecera de cada uno.

## Instalaci√≥n de paquetes

Algunos de los conjuntos se encuentran en paquetes que no est√°n instalados por defecto. Para instalarlos, podemos usar la funci√≥n `renv::install()`.

Aprovecho para mencionar que `BiocManager` es un paquete que nos permite instalar paquetes de datos gen√≥micos, como `biocLite`.

```{r eval = FALSE}
renv::install("palmerpenguins")
renv::install("BiocManager")
BiocManager::install()
# BiocManager::install("biocLite") # Esto es un poco diferente de lo habitual
```

## iris

```{r}
head(iris)
```

## palmerpenguins

```{r}
library(palmerpenguins)
head(penguins)
```

## PlantGrowth

```{r}
head(PlantGrowth)
```

## ChickWeight

```{r}
head(ChickWeight)
```

## esoph

```{r}
head(esoph)
```

## BiocManager

En teor√≠a nos permite generar datos gen√≥micos, pero no he podido pararme a ver c√≥mo funciona.

```{r eval = FALSE}
library(BiocManager)
BiocManager::install("airway") # Instalar y cargar paquete
library(airway)

data("airway") # Cargar dataset

# Convertir a un data frame para ML
df <- tibble::tibble(assay(airway))
df$condition <- as.factor(airway$dex)  # Variable de clasificaci√≥n

head(df)
```

# Objetivo del ML

## Objetivo del ML

Supervisado: predecir una variable objetivo a partir de un conjunto de caracter√≠sticas.

No supervisado: encontrar patrones y estructuras en los datos.

## Ejemplo

Supervisado: tenemos un conjunto de datos con las caracter√≠sticas de diferentes flores y la longitud de su s√©palo. Queremos predecir la longitud del s√©palo bas√°ndonos en las dem√°s caracter√≠sticas. Ejemplo: modelos lineal.

No supervisado: tenemos un conjunto de datos con las caracter√≠sticas de diferentes flores, pero no tenemos una variable objetivo. Queremos agrupar las flores en diferentes categor√≠as bas√°ndonos en sus caracter√≠sticas. Ejemplo: an√°lisis de componentes principales (PCA).

# Modelos Lineales

## Modelos Lineales

Los modelos lineales son una herramienta fundamental en Machine Learning. Aqu√≠, usaremos el conjunto de datos `iris` para predecir la longitud del s√©palo (`Sepal.Length`) basado en las dem√°s caracter√≠sticas.

```{r linear-model, echo=TRUE, message=FALSE, warning=FALSE}
# Cargar los datos
data(iris)

# Ajustar un modelo lineal
modelo_lineal <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris)
```

## Modelos Lineales

Podemos ver un resumen del modelo:

```{r, echo=FALSE}
summary(modelo_lineal)
```

## Visualizaci√≥n del Modelo Lineal

Es importante visualizar los resultados del modelo para comprender su desempe√±o.

```{r plot-linear, eval=FALSE, message=FALSE, warning=FALSE}
# Predicciones
predicciones <- predict(modelo_lineal, iris)

# Gr√°fico: valores reales vs predicciones
plot(iris$Sepal.Length, predicciones, 
     xlab = "Valores reales", ylab = "Predicciones",
     main = "Modelo Lineal: Valores Reales vs Predicciones")
abline(0, 1, col = "red")
```

## Visualizaci√≥n del Modelo Lineal

```{r , echo=FALSE, message=FALSE, warning=FALSE}
# Predicciones
predicciones <- predict(modelo_lineal, iris)

# Gr√°fico: valores reales vs predicciones
plot(iris$Sepal.Length, predicciones, 
     xlab = "Valores reales", ylab = "Predicciones",
     main = "Modelo Lineal: Valores Reales vs Predicciones")
abline(0, 1, col = "red")
```

## Visualizaci√≥n del error

```{r}
# Gr√°fico: valores reales vs errores
errores <- iris$Sepal.Length - predicciones
plot(iris$Sepal.Length, errores, 
     xlab = "Valores reales", ylab = "Errores",
     main = "Modelo Lineal: Valores Reales vs Errores")
abline(0, 0, col = "red")
```

# Splines

## Splines

Los splines permiten modelar relaciones no lineales entre las variables. Aqu√≠ los usaremos para explorar c√≥mo se relaciona la longitud del s√©palo (`Sepal.Length`) con la longitud del p√©talo (`Petal.Length`).

```{r splines, eval=FALSE, message=FALSE, warning=FALSE}
library(splines)

# Ajustar un modelo con splines
modelo_splines <- lm(Sepal.Length ~ bs(Petal.Length, df = 4), data = iris)

# Resumen del modelo
summary(modelo_splines)
```

## Splines

```{r , echo=FALSE, message=FALSE, warning=FALSE}
library(splines)

# Ajustar un modelo con splines
modelo_splines <- lm(Sepal.Length ~ bs(Petal.Length, df = 4), data = iris)

# Resumen del modelo
summary(modelo_splines)
```

## Visualizaci√≥n de Splines

Visualicemos c√≥mo los splines capturan relaciones no lineales en los datos.

```{r plot-splines, eval=FALSE, message=FALSE, warning=FALSE}
# Crear datos para predicciones
nuevos_datos <- data.frame(Petal.Length = seq(min(iris$Petal.Length), max(iris$Petal.Length), length.out = 100))
nuevos_datos$prediccion <- predict(modelo_splines, nuevos_datos)

# Gr√°fico
plot(iris$Petal.Length, iris$Sepal.Length, 
     xlab = "Longitud del P√©talo", ylab = "Longitud del S√©palo", 
     main = "Modelo con Splines")
lines(nuevos_datos$Petal.Length, nuevos_datos$prediccion, col = "blue", lwd = 2)
```

## Visualizaci√≥n de Splines

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Crear datos para predicciones
nuevos_datos <- data.frame(Petal.Length = seq(min(iris$Petal.Length), max(iris$Petal.Length), length.out = 100))
nuevos_datos$prediccion <- predict(modelo_splines, nuevos_datos)

# Gr√°fico
plot(iris$Petal.Length, iris$Sepal.Length, 
     xlab = "Longitud del P√©talo", ylab = "Longitud del S√©palo", 
     main = "Modelo con Splines")
lines(nuevos_datos$Petal.Length, nuevos_datos$prediccion, col = "blue", lwd = 2)
```

# KNN

## KNN

Este modelo, el de los N vecinos m√°s cercanos (K nearest neighbors), es un algoritmo de aprendizaje supervisado que se utiliza para **clasificaci√≥n** y regresi√≥n. En este caso, vamos a usarlo para clasificar las flores del conjunto de datos `iris`.

```{r}
# Cargar el paquete
library(class)

# Ajustar el modelo
modelo_knn <- knn(train = iris[, -5], test = iris[, -5], cl = iris$Species, k = 3)
modelo_knn
```

## Visualizaci√≥n del error de clasificaci√≥n

Se usa pr√°cticamente siempre una matriz de confusi√≥n:

```{r}
# Resultados
table(modelo_knn, iris$Species)
```

## Visualizaci√≥n del error de clasificaci√≥n

Podemos visualizar dichos resultados de otras formas, empleando `geom_tile()`, por ejemplo.

```{r}
conf_matrix <- table(modelo_knn, iris$Species) %>% 
  as.data.frame()

ggplot(conf_matrix, aes(x = modelo_knn, y = Var2, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1) +
  theme_minimal() +
  labs(title = "Matriz de Confusi√≥n", x = "Predicci√≥n", y = "Real")
```

# Problema de unificaci√≥n

## Problema de unificaci√≥n

Hemos visto que estos paquetes, aunque compartan la idea que hay detr√°s, presentan una sintaxis b√°sica muy diferente. Para evitar estas dificultades de propone emplear el paquete `tidymodels`, el equivalente de `tidyverse` para modelos predictivos.

Sin `tidymodels` hemos empleado el siguiente c√≥digo:

```{r eval=FALSE}
modelo_lineal <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris)
modelo_splines <- lm(Sepal.Length ~ bs(Petal.Length, df = 4), data = iris)
modelo_knn <- knn(train = iris[, -5], test = iris[, -5], cl = iris$Species, k = 3)
```

## Problema de unificaci√≥n

Con `tidymodels` emplear√≠amos el siguiente:

```{r eval=FALSE}
renv::install("tidymodels")
renv::install("kknn") # Va aparte
```


```{r}
library(tidymodels)

## Selecci√≥n de modelos
# Crear un modelo lineal
modelo_lineal <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

# Crear un modelo con splines
modelo_splines <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression") %>%
  set_args(degree = 4)

# Crear un modelo KNN
modelo_knn <- nearest_neighbor(weight_func = "rectangular", neighbors = 3) %>%
  set_engine("kknn") %>%
  set_mode("regression") # 

## Ajuste de modelos
my_workflow = workflow(Sepal.Length ~ .)

resultados = list()

resultados$lineal = my_workflow %>% 
  add_model(modelo_lineal) %>%
  fit(data = iris)

resultados$splines = my_workflow %>% 
  add_model(modelo_splines) %>%
  fit(data = iris)

resultados$knn = my_workflow %>% 
  add_model(modelo_knn) %>%
  fit(data = iris)

for (i in 1:length(resultados)) {
  print(resultados[[i]])
}
```

Ahora podr√≠amos visualizar los resultados:

```{r}
graficas = list()

## Predicciones
for (i in seq_along(resultados)) { # 1:length(resultados)
  predicciones <- predict(resultados[[i]], new_data = iris)
  
  iris %>% 
    bind_cols(predicciones) %>% 
    ggplot(aes(x = Sepal.Length, y = .pred)) +
      geom_point() +
      geom_abline(intercept = 0, slope = 1, color = "red") +
      labs(title = paste("Modelo", i, ": Valores Reales vs Predicciones"),
           x = "Valores Reales", y = "Predicciones")
}
```

# Ejercicios

## Ejercicios

1. Ajusta un modelo lineal para predecir la anchura del s√©palo (`Sepal.Width`) usando las dem√°s variables.
2. Experimenta con diferentes valores de grados de libertad (`df`) en el modelo de splines. ¬øC√≥mo cambia el ajuste?

# Ejercicios Avanzados

## Ejercicios Avanzados

1. Implementa validaci√≥n cruzada para comparar el desempe√±o del modelo lineal y el modelo de splines.
2. Obt√©n varias m√©tricas de error, tales como el error cuadr√°tico medio, para evaluar los modelos.
3. Crea un gr√°fico interactivo usando el paquete `plotly` para explorar las predicciones del modelo de splines.
